#! /opt/stack/bin/python3
# -*- python -*-
#
# @copyright@
# Copyright (c) 2006 - 2019 Teradata
# All rights reserved. Stacki(r) v5.x stacki.com
# https://github.com/Teradata/stacki/blob/master/LICENSE.txt
# @copyright@

import os
import subprocess
import tempfile
import pkg_resources
from typing import List
import argparse
from pathlib import Path
import dataclasses
import tomlkit

@dataclasses.dataclass
class Package:
	"""A dataclass container to hold the package metadata we need to process our python dependencies."""
	# Key is the case insensitive identifier for the package, normally name.casefold() or similar.
	key: str
	# Name is the canonical, potentially camel cased name.
	name: str
	master: bool
	bootstrap: bool
	appliances: List[str]
	dependencies: List["Package"]
	version: str
	package_license: str = dataclasses.field(default = "")
	url: str = dataclasses.field(default = "")


def populate_metadata(package, distributions):
	"""Given a package and some parsed distribution information, try to populate the package's license and url fields."""
	distribution = distributions[package.key]
	package_info_key = "PKG-INFO"
	metadata_key = "METADATA"

	# Try the various metadata name keys, but just return the package if we can't find it.
	if distribution.has_metadata(package_info_key):
		distribution_metadata_lines = distribution.get_metadata_lines(package_info_key)
	elif distribution.has_metadata(metadata_key):
		distribution_metadata_lines = distribution.get_metadata_lines(metadata_key)
	else:
		return package

	# Found some metadata, lets parse it.
	for line in distribution_metadata_lines:
		try:
			# Lines we care about are written as <key>:<value>
			key, value = line.split(":", maxsplit = 1)
			key = key.casefold().strip()
			value = value.strip()
		except ValueError:
			continue

		# Use the home-page metadata as the URL.
		if key == "home-page":
			package.url = value

		# Read the license. This key takes less precedence than the `Classifier: License` key.
		if key == "license":
			package.package_license = value

		# Read the license. This key takes more precedence than the `License` key.
		if key == "classifier" and value.casefold().startswith("license"):
			package.package_license = value

	return package

def get_dependencies(parent_package_dict, locked_packages, distributions, bootstrap, appliances):
	"""Given a parent package dictionary from poetry.lock, return a list of Package dataclasses that represent its dependencies."""
	dependencies = []
	# If there are no dependencies, return an empty list
	if "dependencies" not in parent_package_dict:
		return dependencies

	# Otherwise, build out that set of dependencies.
	for package_dict in locked_packages:
		package_key = package_dict["name"]
		# If the package isn't one of the parent dependencies, don't create a Package for it.
		if package_key not in parent_package_dict["dependencies"]:
			continue

		# If the package didn't get installed, I.E. due to markers disabling it for the current environment,
		# don't add it to our package list.
		if package_key not in distributions:
			continue

		dependency = Package(
			key = package_key,
			# We must use the canonical, potentially camel cased name because RPMs are case sensitive.
			# I'm not bitter at all.
			name = distributions[package_key].project_name,
			version = package_dict["version"],
			master = False,
			bootstrap = bootstrap,
			appliances = appliances,
			# Recurse to fill out this dependency's dependencies, passing down the bootstrap and appliances.
			dependencies = get_dependencies(
				parent_package_dict = package_dict,
				locked_packages = locked_packages,
				distributions = distributions,
				bootstrap = bootstrap,
				appliances = appliances,
			),
		)
		# Try to find the metadata and parse the license and url, and then append the package to the list.
		dependency = populate_metadata(package = dependency, distributions = distributions)
		dependencies.append(dependency)

	return dependencies

def build_package_list(locked_packages, dependencies, stacki_metadata, distributions, bootstrap_only):
	"""Build a list of packages and all their dependencies.

	This returns a list of Package objets which are the top level packages as defined in pyproject.toml. These packages have
	a dependencies attribute which is a list of Package objects that are their direct dependencies. Each of those Package objects
	may have a non-empty dependencies list and so on.
	"""
	# Start the package tree with the master packages, which are defined in the top level dependencies from pyproject.toml.
	top_level_packages = []
	for package_dict in locked_packages:
		package_key = package_dict["name"]
		# Don't create a top level package if this is not in the top level dependencies.
		if package_key not in dependencies:
			continue

		bootstrap_value = stacki_metadata[package_key].get("bootstrap", False)
		# If we're configured to do bootstrap packages only, skip all non-bootstrap packages.
		if bootstrap_only and not bootstrap_value:
			continue

		# If the package didn't get installed, I.E. due to markers disabling it for the current environment,
		# don't add it to our package list.
		if package_key not in distributions:
			continue

		appliances_value = stacki_metadata[package_key].get("appliances", [])
		top_level_package = Package(
			key = package_key,
			# We must use the canonical, potentially camel cased name because RPMs are case sensitive.
			# I'm not bitter at all.
			name = distributions[package_key].project_name,
			version = package_dict["version"],
			master = True,
			bootstrap = bootstrap_value,
			appliances = appliances_value,
			# Get this master packages dependencies, and the sub dependencies of those dependencies, and so on.
			# This ends up chaining all of the master properties such as bootstrap and appliance names down to
			# this master package's children, children's children, and so on.
			dependencies = get_dependencies(
				parent_package_dict = package_dict,
				locked_packages = locked_packages,
				distributions = distributions,
				bootstrap = bootstrap_value,
				appliances = appliances_value,
			),
		)
		# Try to find the metadata and parse the license and url, and then append the package to the list.
		top_level_package = populate_metadata(package = top_level_package, distributions = distributions)
		top_level_packages.append(top_level_package)

	return top_level_packages

def write_makefiles(package, package_prefix):
	"""Write the makefiles for this package, all its dependencies, all its dependencies dependencies, and so on."""
	srcdir = Path("src") / package.name
	# Don't overwrite existing stuff for this specific package, but do potentially
	# write dependencies of this package that might be missing.
	if not srcdir.exists():
		srcdir.mkdir(parents = True)
		with srcdir.joinpath("Makefile").open("w") as makefile:
			makefile.write("PKGROOT  = /opt/stack\n")
			makefile.write(f"ROLLROOT = {os.environ['ROLLROOT']}/../..\n")
			makefile.write("\n")
			makefile.write("include $(STACKBUILD)/etc/CCRules.mk\n")
			makefile.write("\n")
			makefile.write("build:\n")
			makefile.write("\n")
			makefile.write("install::\n")
			makefile.write(f"\t$(PY.PATH) -mpip install --no-warn-script-location -I --no-deps --root=$(ROOT) {package.name}==$(VERSION)\n")
			if package.bootstrap:
				makefile.write("\n")
				makefile.write("bootstrap: install-rpm\n")

		with srcdir.joinpath("version.mk").open("w") as ver:
			ver.write('NAME=%s-%s\n' % (package_prefix, package.name))
			ver.write('VERSION=%s\n' % package.version)

	# Now write the makefiles for our dependencies, and our dependencies dependencies, and so on.
	for dependency in package.dependencies:
		write_makefiles(package = dependency, package_prefix = package_prefix)

def _write_node_packages(package, package_prefix, node_file, indent):
	"""Recurses through the chain of dependencies to write all packages into the node file."""
	# Write this package.
	node_file.write(f"{indent}{package_prefix}-{package.name}\n")

	# Write all of the dependencies of this package.
	for dependency in package.dependencies:
		_write_node_packages(
			package = dependency,
			package_prefix = package_prefix,
			node_file = node_file,
			# Extra indent to delineate master package from its dependencies for humans.
			indent = "\t\t",
		)

def _write_manifest(package, package_prefix, manifest_file):
	"""Recurses through the chain of dependencies to write all packages into the manifest file."""
	# Write this package.
	manifest_file.write(f"{package_prefix}-{package.name}\n")

	# Write all of the dependencies of this package.
	for dependency in package.dependencies:
		_write_manifest(package = dependency, package_prefix = package_prefix, manifest_file = manifest_file)

def get_licenses(package):
	"""Get the licenses of the package and all its dependencies."""
	licenses = {}
	# Add the license for this package.
	licenses[package.name] = (package.version, package.package_license, package.url)

	# Get all the licenses of the dependencies.
	for dependency in package.dependencies:
		licenses.update(get_licenses(package = dependency))

	return licenses

if __name__ == "__main__":
	parser = argparse.ArgumentParser(
		description = (
			"Resolves required foundation python dependencies for stacki and builds "
			"requisite node, graph, and make files."
		),
	)
	parser.add_argument(
		"release",
		help = "The OS release this is being built on. Required to exclude packages that don't work on SLES 11.",
	)
	parser.add_argument(
		"--bootstrap",
		action = "store_true",
		help = "Only resolve bootstrap packages",
	)
	args = parser.parse_args()

	lockfile_path = Path("poetry.lock")
	if not lockfile_path.exists():
		print("\nUsing poetry to lock dependencies and install them.")
		print(
			"\nThe lockfile appears to not exist. This will generate"
			" a new poetry.lock file which must be committed to source control."
		)
	else:
		print("\nUsing poetry to install locked dependencies.")

	with tempfile.TemporaryDirectory() as temp_dir:
		# Configure poetry to use the temporary directory for this venv.
		subprocess.run(
			["/opt/stack/bin/poetry", "config", "--no-interaction", "virtualenvs.path", temp_dir],
			check = True,
		)
		# Install all the packages in a local venv so we can parse some
		# extra data from them, like licenses. If the lockfile does not
		# exist yet, this will lock the dependencies and generate a
		# lockfile.
		#
		# We only have to pass release here because of SLES 11 not supporting libvirt-python.
		subprocess.run(["/opt/stack/bin/poetry", "install", "--no-interaction", "--extras", args.release], check = True)

		# Read in the pyproject.toml and poetry.lock files.
		project_toml = tomlkit.parse(Path("pyproject.toml").read_text())
		project_lockfile = tomlkit.parse(lockfile_path.read_text())
		# The dependency names are sometimes camel case in some contexts and lowercase in others.
		# Normalize all the dependency names since pip/poetry doesn't care.
		dependencies = {
			key.casefold(): value
			for key, value in project_toml["tool"]["poetry"]["dependencies"].items()
			# For some reason this tool wants the python version here, so make sure we don't
			# treat it as a dependency.
			if key.casefold() != "python"
		}
		# Same for the locked packages.
		locked_packages = project_lockfile["package"]
		for package_dict in locked_packages:
			package_dict["name"] = package_dict["name"].casefold()
			# The dependencies dictionary is where I've seen the keys, I.E. dependency names,
			# be camel cased.
			if "dependencies" in package_dict:
				package_dict["dependencies"] = {
					key.casefold(): value
					for key, value in package_dict["dependencies"].items()
				}
		# And be sure to normalize the stacki-metadata stuff too.
		stacki_metadata = {
			key.casefold(): value
			for key, value in project_toml["stacki-metadata"].items()
		}
		# Ensure that the packages in stacki-metadata section of pyproject.toml all exist in the tool.poetry.dependencies section.
		for package in stacki_metadata:
			if package not in dependencies:
				raise ValueError(f"The package {package} in stacki-metadata is not present in tool.poetry.dependencies")

		# Ensure the reverse.
		for package in dependencies:
			if package not in stacki_metadata:
				raise ValueError(f"The package {package} in tool.poetry.dependencies is not present in stacki-metadata")

		# Get the path to site-packages.
		site_packages = list(Path(temp_dir).glob("**/site-packages"))
		if len(site_packages) != 1:
			raise ValueError(f"Unable to find the virtualenv's site-packages folder. Found: {site_packages if site_packages else 'nothing'}")

		site_packages = site_packages[0]

		# To get all the distribution information from the venv, and make it a dictionary keyed by
		# the distributions key attribute, which is used for case insensitive compares.
		venv_distributions = {
			distribution.key: distribution
			for distribution in pkg_resources.find_distributions(site_packages)
		}

		# Build the combined package list from all the data sources.
		print('\nBuild the package list')
		package_list = build_package_list(
			locked_packages = locked_packages,
			dependencies = dependencies,
			stacki_metadata = stacki_metadata,
			distributions = venv_distributions,
			bootstrap_only = args.bootstrap,
		)

	print('\nWrite the licenses')
	# Write out the computed license information
	package_license = {}
	for package in package_list:
		package_license.update(get_licenses(package = package))

	rows   = []
	widths = [0, 0, 0, 0]
	for name in sorted(package_license.keys()):
		rows.append([name, package_license[name][0], package_license[name][1], package_license[name][2]])
	for row in rows:
		for i in range(0, 4):
			if len(row[i]) > widths[i]:
				widths[i] = len(row[i])

	with Path("LICENSE.txt").open("w") as text:
		for row in rows:
			text.write(f'{row[0].ljust(widths[0])} {row[1].ljust(widths[1])} {row[2].ljust(widths[2])} {row[3]}\n')

	print('\nWrite the makefiles')
	# Build the src/ directories
	package_prefix = "foundation-python"
	for package in package_list:
		write_makefiles(package = package, package_prefix = package_prefix)

	print('\nWrite the node files')
	# Create node files
	nodedir = Path("nodes")
	nodedir.mkdir(exist_ok = True)
	# This loop creates a node file per top level package that contains package directives for it
	# and all of its nested dependencies.
	node_name_template = "{package_prefix}-pip2src-{package_name}"
	for package in package_list:
		node_name = node_name_template.format(package_prefix = package_prefix, package_name = package.name)
		with nodedir.joinpath(f"{node_name}.xml").open("w") as node:
			node.write("<stack:stack><stack:package>\n")
			_write_node_packages(
				package = package,
				package_prefix = package_prefix,
				node_file = node,
				indent = "\t",
			)
			node.write("</stack:package></stack:stack>\n")

	print('\nWrite the graph files')
	# Create graph files
	graphdir = Path("graph")
	graphdir.mkdir(exist_ok = True)
	with graphdir.joinpath(f"{package_prefix}-pip2src.xml").open("w") as graph:
		graph.write("<graph>\n")
		# Write an edge for each top level package based on its appliances.
		for package in package_list:
			node_name = node_name_template.format(package_prefix = package_prefix, package_name = package.name)
			for appliance in package.appliances:
				graph.write(f'\t<edge from="{package_prefix}-{appliance}" to="{node_name}"/>\n')

			if package.appliances:
				graph.write("\n")

		graph.write("</graph>\n")

	print('\nWrite the manifests')
	# Create manifests
	manifestdir = Path("manifest.d")
	manifestdir.mkdir(exist_ok = True)
	for package in package_list:
		with manifestdir.joinpath(f"{package_prefix}-{package.name}.manifest").open("w") as manifest:
			_write_manifest(package = package, package_prefix = package_prefix, manifest_file = manifest)

	print('\n\n')
